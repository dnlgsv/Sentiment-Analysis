{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download NLTK data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Settings for visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ajaykarthick/imdb-movie-reviews\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First glance at the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is pretty big, so I will load only test data for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(\"First few entries in the dataset:\")\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I see that review with index 4 has html tags, so let's take a closser look at it "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.iloc[4]['review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yes, the review has html tags, but it is not a big deal, because we can remove them easily if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Label:\", df.iloc[4]['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interesting, while it is not obligatory to use \"1\" for positive and \"0\" for negative, it is a common practice. However this dataset uses \"0\" for positive and \"1\" for negative reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statisctics and distributions of the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quality check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gladly, there are no missing values in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check for duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicate reviews\n",
        "duplicate_count = df.duplicated(subset='review').sum()\n",
        "print(f\"\\nNumber of duplicate reviews: {duplicate_count}\")\n",
        "\n",
        "# Remove duplicates if any\n",
        "if duplicate_count > 0:\n",
        "    df = df.drop_duplicates(subset='review').reset_index(drop=True)\n",
        "    print(\"Duplicates have been removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 16 duplicates in the dataset. While it is not a big deal, I will remove them, since they can skew analysis, models training and evaluation of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Class distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# Visualize class distribution\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title('Sentiment Class Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset is balanced, so we don't need to worry about class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyzing Review Lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate review lengths (number of words)\n",
        "df['review_length'] = df['review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Basic statistics of review lengths\n",
        "print(\"\\nReview Length Statistics:\")\n",
        "print(df['review_length'].describe())\n",
        "\n",
        "# Visualize review length distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['review_length'], bins=50, kde=True)\n",
        "plt.title('Review Length Distribution')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boxplot of review length by sentiment\n",
        "sns.boxplot(x='label', y='review_length', data=df)\n",
        "plt.title('Review Length by Sentiment')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Words')\n",
        "os.makedirs('../results/eda', exist_ok=True)\n",
        "plt.savefig('../results/eda/review_length_by_sentiment.png', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is no big difference in review lengths by sentiment, so we don't need to worry about it while splitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lexical Analysis (Most Common Words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function to preprocess text data\n",
        "    \"\"\"\n",
        "    \n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing\n",
        "df['tokens'] = df['review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df['label'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Most Common Words in Positive and Negative Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate positive and negative reviews\n",
        "positive_reviews = df[df['label'] == 0]\n",
        "negative_reviews = df[df['label'] == 1]\n",
        "\n",
        "# Get all tokens for each class\n",
        "positive_tokens = [token for tokens in positive_reviews['tokens'] for token in tokens]\n",
        "negative_tokens = [token for tokens in negative_reviews['tokens'] for token in tokens]\n",
        "\n",
        "# Get most common words\n",
        "positive_counter = Counter(positive_tokens)\n",
        "negative_counter = Counter(negative_tokens)\n",
        "\n",
        "print(\"\\nMost common words in positive reviews:\")\n",
        "print(positive_counter.most_common(20))\n",
        "\n",
        "print(\"\\nMost common words in negative reviews:\")\n",
        "print(negative_counter.most_common(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 10\n",
        "# Get the N most common words for positive and negative reviews\n",
        "positive_common_words = positive_counter.most_common(N)\n",
        "negative_common_words = negative_counter.most_common(N)\n",
        "\n",
        "# Separate words and their counts for positive and negative reviews\n",
        "positive_words, positive_counts = zip(*positive_common_words)\n",
        "negative_words, negative_counts = zip(*negative_common_words)\n",
        "\n",
        "# Plot for positive words\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.barh(positive_words, positive_counts, color='#a4c5ea')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Most Common Words in Positive Reviews')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.savefig('../results/eda/most_common_words_in_positive_reviews.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot for negative words\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.barh(negative_words, negative_counts, color='#bca9e1')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Most Common Words in Negative Reviews')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.savefig('../results/eda/most_common_words_in_negative_reviews.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizing Word Clouds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate word cloud for positive reviews\n",
        "positive_text = ' '.join(positive_tokens)\n",
        "positive_wordcloud = WordCloud(width=800, height=400).generate(positive_text)\n",
        "\n",
        "plt.figure(figsize=(15, 7.5))\n",
        "plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Positive Reviews')\n",
        "plt.savefig('../results/eda/wordcloud_for_positive_tokens.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Generate word cloud for negative reviews\n",
        "negative_text = ' '.join(negative_tokens)\n",
        "negative_wordcloud = WordCloud(width=800, height=400).generate(negative_text)\n",
        "\n",
        "plt.figure(figsize=(15, 7.5))\n",
        "plt.imshow(negative_wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Negative Reviews')\n",
        "plt.savefig('../results/eda/wordcloud_for_negative_tokens.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions:\n",
        "\n",
        "1. The dataset is balanced, so we don't need to worry about class imbalance.\n",
        "2. There are no missing values in the dataset.\n",
        "3. There are only 16 duplicates in the dataset, so it will not significantly affect any metrics.\n",
        "4. There is no big difference in review lengths by sentiment, so we don't need to worry about it while splitting.\n",
        "5. The most common words in positive and negative reviews are pretty similar, so we need to be careful\n",
        "6. There are some unique words in positive and negative reviews, so it is possible to use encoding models to create embeddings for them and train a simple logreg model to predict sentiment - it can be a good baseline model.\n",
        "7. There are some html tags in the reviews, so we need to remove them before training models.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
